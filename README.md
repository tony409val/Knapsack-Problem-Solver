# 0/1 Knapsack Problem Solver using Machine Learning

This project is a research-focused application designed to explore and compare three distinct Machine Learning and Bio-inspired computing architectures for solving the **1-Dimensional 0-1 Knapsack Problem**.

The application features a graphical user interface (GUI) built with `tkinter` that allows users to train models, evaluate performance against standard algorithms (Greedy and Optimal/CBC), and visualize decision-making processes in real-time.

## üìå Features

* **Three Distinct Architectures:** Implementations derived from specific research papers covering GRU-based Supervised Learning, Transformer-based Reinforcement Learning, and Evolutionary Spiking Neural P Systems.
* **Interactive GUI:** A central dashboard to select dataset parameters, choose models, and trigger training or testing loops.
* **Real-time Visualization:** Live plotting of item selection, approximation ratios, and reward convergence using `matplotlib`.
* **Dataset Variety:** Support for Uncorrelated (UC), Strongly Correlated (SC), and Subset Sum (SS) knapsack instances.
* **Benchmarking:** Automated comparison against a Greedy heuristic and the Optimal solution (computed via `pulp`/CBC).

---

##  Model Architectures

### Model 1: GRU-Based Seq2Seq (Supervised)
A Sequence-to-Sequence neural network that treats the knapsack problem as a pointer-network-style classification task.
* **Source:** Derived from *"Neural Knapsack: A Neural Network Based Solver for the Knapsack Problem"* [1].
* **Architecture:** Consists of a Memory Constructor, a **GRU Encoder** to process item features, an **Attention Mechanism** to weigh item importance, and a **GRU Decoder** to output inclusion probabilities.
* **Training:** Supervised learning using Binary Cross-Entropy Loss against optimal solutions generated by the CBC solver.

### Model 2: Transformer-Based RL (Unsupervised)
A Reinforcement Learning approach where an agent learns to construct a solution step-by-step using a Transformer architecture.
* **Source:** Based on research published in *Concurrency and Computation: Practice and Experience* [2].
* **Architecture:** Uses a **Transformer Encoder** as the Deep Q-Network (DQN) to process the state (capacities, bag weight, remaining steps).
* **Training:** Q-Learning with an Epsilon-Greedy strategy and Experience Replay. The model receives a positive reward for adding feasible items and a negative penalty for skipping valuable items.

### Model 3: DAO-SNPS (Evolutionary)
A Distributed Active Optimization Spiking Neural P System.
* **Source:** Derived from *"DAO-SNPS: Distributed active optimization spiking neural P systems"* [3].
* **Architecture:** A population-based bio-inspired algorithm using subpopulations of neurons (solutions).
* **Mechanism:** Implements probabilistic firing rules, mutation, and **migration** (information exchange) between subpopulations to evolve towards an optimal binary configuration.

---

## üõ†Ô∏è Installation & Requirements

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/yourusername/knapsack-ml-solver.git](https://github.com/tony409val/knapsack-ml-solver.git)
    cd knapsack-ml-solver
    ```

2.  **Install dependencies:**
    Ensure you have Python installed. Install the required libraries:
    ```bash
    pip install torch numpy matplotlib pulp
    ```
    *Note: The `tkinter` library is usually included with standard Python installations.*

3.  **Solver Requirement:**
    The data generator relies on the `pulp` library, which requires a solver. The default used is CBC (Coin-OR Branch and Cut), which usually comes with PuLP.

---

## üöÄ Usage

### 1. Data Generation
Before using the UI, you must generate the datasets. The UI does not generate data dynamically; it loads from pre-saved pickle files.
1.  Open `data_generator.py`.
2.  Uncomment the desired data configuration (Training or Evaluation).
3.  Run the generator script to create training and evaluation data:
```bash
python data_generator.py
```

This will create files (e.g., training_data_uc_10.pkl) in your directory.

### 2. Running the Application
Launch the main GUI:
```bash
python main.py
```

### 3. Workflow via GUI
1. Select Parameters:

* **Item Volume:** Number of items per knapsack instance (e.g., 10, 50, 100).

* **Data Type:**

  * **UC (Uncorrelated)**

  * **SC (Strongly Correlated)**

  * **SS (Subset Sum)**

* **Select Model:** Choose between Model 1, Model 2, or Model 3.

2. **Train:** Click "Train and Save Model". This initiates the training loop. A visualization window will pop up showing the approximation ratio improving over epochs/episodes.

3. **Test:** Click "Test Random Sample" to load a trained model and solve a single random instance. It displays the Model's solution vs. the Optimal (CBC) solution.

4. **Evaluate:** Click "Evaluate Model" to run a batch evaluation. This provides aggregate metrics like Average Approximation Ratio, Infeasibility Rate, and Runtime.

## üìÇ Project Structure

* **`main.py`**: Entry point for the GUI application.
* **`data_generator.py`**: Generates synthetic knapsack instances and solves them for ground truth.
* **`visual.py`**: Handles matplotlib animations for the knapsack contents and training curves.
* **`utils.py`**: Helper functions for loading/saving data and greedy decoding logic.
* **`evaluation.py` / `test.py`**: Logic for benchmarking trained models against validation sets.
* **Model Files**:
    * `model_1_*.py`: Architecture and trainer for the GRU model.
    * `model_2_*.py`: Architecture, environment, and trainer for the RL Transformer.
    * `model_3_*.py`: Implementation of the DAO-SNPS evolutionary algorithm.

---

## üìö References

1.  H. A. A. Nomer, K. A. Alnowibet, A. Elsayed and A. W. Mohamed, "Neural Knapsack: A Neural Network Based Solver for the Knapsack Problem," in *IEEE Access*, vol. 8, pp. 224200-224210, 2020. [DOI: 10.1109/ACCESS.2020.3044005](https://doi.org/10.1109/ACCESS.2020.3044005)
2.  Research on Transformer-based RL for Knapsack Problems. [DOI: 10.1002/cpe.6509](https://doi.org/10.1002/cpe.6509)
3.  Research on Distributed Active Optimization Spiking Neural P Systems. *Information Sciences*, 2022. [DOI: 10.1016/j.ins.2022.03.007](https://doi.org/10.1016/j.ins.2022.03.007)

---

## ‚ö†Ô∏è Disclaimer

This project is created for **research purposes**. While the models utilize advanced architectures, the 0/1 Knapsack problem is NP-Complete. These ML models provide *approximate* solutions. The "Optimal" solution used for benchmarking is derived from the exact solver (CBC) via the `pulp` library.
